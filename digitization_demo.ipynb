{"cells":[{"cell_type":"markdown","source":["# Automating the Digitization of Drawn Figures on Maps"],"metadata":{"nteract":{"transient":{"deleting":false}}}},{"cell_type":"markdown","source":["### Libraries/Dependencies used\r\n","\r\n","**OpenCV** for color extraction and image detection <br>\r\n","**Numpy** for numbers and array manipulation <br>\r\n","**glob** for directory navigation <br>\r\n","**os** for environment variable use <br>\r\n","**azureml** for workspace connectivity and dataset creation and access"],"metadata":{"nteract":{"transient":{"deleting":false}}}},{"cell_type":"code","source":["import numpy as np\r\n","import glob\r\n","import cv2\r\n","import os"],"outputs":[],"execution_count":1,"metadata":{}},{"cell_type":"markdown","source":["### Subscription Information & Datastore Access\r\n","\r\n","Necessary for workspace-storage connectivity and import of data\r\n","\r\n","For questions on how to get these, check the [**README file**](./README.md)\r\n"],"metadata":{"nteract":{"transient":{"deleting":false}}}},{"cell_type":"code","source":["#Access to subscription information\r\n","sub_id = os.getenv(\"SUBSCRIPTION_ID\", default=\"<YOUR_SUBSCRIPTION_ID>\")\r\n","rsc_group = os.getenv(\"RESOURCE_GROUP\", default=\"<YOUR_RESOURCE_GROUP>\")\r\n","ws_name = os.getenv(\"WORKSPACE_NAME\", default=\"<YOUR_CURRENT_WORKSPACE>\")\r\n","ws_region = os.getenv(\"WORKSPACE_REGION\", default=\"eastus2\")\r\n","\r\n","#Access to storage information\r\n","azure_storage_account_name = \"<YOUR_STORAGE_ACCOUNT_NAME>\"\r\n","azure_storage_account_key = \"<YOUR_STORAGE_ACCOUNT_KEY>\""],"outputs":[],"execution_count":2,"metadata":{"collapsed":true,"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}}},{"cell_type":"code","source":["#Connecting to a functional workspace \r\n","from azureml.core import Workspace\r\n","from azureml.core import Dataset, Datastore\r\n","from azureml.data.datapath import DataPath\r\n","\r\n","try:\r\n","    ws = Workspace(subscription_id = sub_id, resource_group = rsc_group, workspace_name = ws_name)\r\n","    # write the details of the workspace to a configuration file to the notebook library\r\n","    ws.write_config()\r\n","    print(\"Workspace configuration succeeded. Skip the workspace creation steps below\")\r\n","except:\r\n","    print(\"Workspace not accessible. Change your parameters or create a new workspace below\")\r\n","\r\n","\r\n","# create file dataset from files in datastore\r\n","datastore = Datastore.get(ws, '<NAME_OF_THE_DATASTORE>')\r\n","datastore_path = DataPath(datastore)\r\n","file_dataset = Dataset.File.from_files(path=datastore_path)"],"outputs":[{"output_type":"stream","name":"stdout","text":["Performing interactive authentication. Please follow the instructions on the terminal.\n","To sign in, use a web browser to open the page https://microsoft.com/devicelogin and enter the code A8FQC8CVB to authenticate.\n","Interactive authentication successfully completed.\n","Workspace not accessible. Change your parameters or create a new workspace below\n"]},{"output_type":"error","ename":"NameError","evalue":"name 'ws' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-af74266375d8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# create file dataset from files in datastore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mdatastore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDatastore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mws\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'<NAME_OF_THE_DATASTORE>'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0mdatastore_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatastore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mfile_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdatastore_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'ws' is not defined"]}],"execution_count":3,"metadata":{"collapsed":true,"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}}},{"cell_type":"markdown","source":["## Downloading the Data into our Compute\r\n","\r\n","This step should only be done when there is new data to be processed, or the Data Store has changed. This downloads the previously created [File Dataset](https://docs.microsoft.com/python/api/azureml-core/azureml.data.filedataset?view=azure-ml-py?WT.mc_id=mapdigitdemo-github-cxa) into our compute, so that our files may be processed."],"metadata":{"nteract":{"transient":{"deleting":false}}}},{"cell_type":"code","source":["#Download the data into the AzureML compute instance.\r\n","file_list = file_dataset.download(target_path=\"<DATA_FOLDER>\")"],"outputs":[],"execution_count":null,"metadata":{"collapsed":true,"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}}},{"cell_type":"markdown","source":["## Feature Extraction\r\n","\r\n","For this project, we will be extracting drawings based on color using [**OpenCV**](https://docs.opencv.org/3.4/d6/d00/tutorial_py_root.html). <br>\r\n","OpenCV loads images as *numpy* arrays, consisting of RGB values in a 2D matrix. <br>\r\n","Our goal is extracting the pixels that fall within our specified RGB range (BGR as OpenCV formats it this way) and use them to create a mask of the original image."],"metadata":{"nteract":{"transient":{"deleting":false}}}},{"cell_type":"code","source":["#General Purpose Function. Loops over our dataset, reading each image and creating a mask for each of them.\r\n","def color_masking():\r\n","    #Iterating over the test files, would iterate over repo in the future\r\n","    for filename in glob.glob(\"./<DATA_FOLDER>/*.jpg\"):\r\n","        image = cv2.imread(filename)\r\n","        create_mask(image, filename)\r\n"],"outputs":[],"execution_count":null,"metadata":{"collapsed":true,"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}}},{"cell_type":"code","source":["#This function creates the masks from a given set of RGB values. These were determined using a simple color picker on our sample images.\r\n","#FUTURE WORK: Discard the output image creation, use the final coordinates for cross-referencing and creation of GeoJSON objects.\r\n","def create_mask(image, filename):\r\n","\r\n","    #RGB boundaries for the opencv function of inRange.\r\n","    #These values are numpy arrays stored in reverse (BGR)\r\n","    #And represent the limits of what we consider a color. In this case, boundaries[0] = red, boundaries[1] = blue and boundaries[2] = green.\r\n","    color_boundaries = [\r\n","        (\"red\", [17, 15, 100], [100, 106, 250]),\r\n","        (\"blue\", [86, 31, 4], [220, 88, 50]),\r\n","        (\"green\", [57, 64, 36], [105, 125, 58])\r\n","    ]\r\n","\r\n","    for (color, lower, upper) in color_boundaries:\r\n","        lower = np.array(lower, dtype = \"uint8\")\r\n","        upper = np.array(upper, dtype = \"uint8\")\r\n","\r\n","        mask = cv2.inRange(image, lower, upper)\r\n","        #Extract Pixel coordinates from our mask.\r\n","        result = np.where(mask != 0)\r\n","        coordinate_list = list(zip(result[0], result[1]))\r\n","\r\n","        #Mask images called for output visualization. To be discarded for cross-referencing and GeoJSON object creation in future iterations.\r\n","        mask_images(image, mask, color, filename)\r\n","    "],"outputs":[],"execution_count":null,"metadata":{"collapsed":true,"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}}},{"cell_type":"code","source":["#Output visualization function. Currenlty used to showcase the created masks.\r\n","def mask_images(image, mask, color, filename):\r\n","\r\n","    result_img = cv2.bitwise_and(image, image, mask = mask)\r\n","\r\n","    cv2.imwrite(\"./output/\" + color + \"_\" + os.path.basename(filename))"],"outputs":[],"execution_count":null,"metadata":{"collapsed":true,"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}}},{"cell_type":"markdown","source":["## Creating the Color-Masked Images\r\n","\r\n","This will remain as a placeholder output. Currently showcases masks as images."],"metadata":{"nteract":{"transient":{"deleting":false}}}},{"cell_type":"code","source":["color_masking()"],"outputs":[],"execution_count":null,"metadata":{"collapsed":true,"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}}},{"cell_type":"markdown","source":["## Work in Progress:  Coordinate Referencing & Mask Clean Up\r\n","\r\n","The project is nearing completion, missing the coordinate transformation (from pixel coordinates to GPS coordinates) within the actual range of our map's coordinates.\r\n","The step after implies the processing of our masks, mainly to eliminate noise (drawings outside the map). <br>\r\n","\r\n","Next Steps:\r\n","- Accurately match the masks' features with referenced spatial coordinates ([Azure Maps Image Layering](https://docs.microsoft.com/javascript/api/azure-maps-control/atlas.layer.imagelayer?view=azure-maps-typescript-latest&viewFallbackFrom=azure-iot-typescript-latest?WT.mc_id=mapdigitdemo-github-cxa))\r\n","- Clean up of noise (Marking the valid are and eliminating pixels outside of it)\r\n","- Possible: Implementation of Custom Vision model to differentiate between shapes' and their meaning (crosses from polygons)"],"metadata":{"nteract":{"transient":{"deleting":false}}}},{"cell_type":"markdown","source":["LinkedIn: https://www.linkedin.com/in/gcordidoa/"],"metadata":{"nteract":{"transient":{"deleting":false}}}}],"metadata":{"kernelspec":{"name":"python3-azureml","language":"python","display_name":"Python 3.6 - AzureML"},"language_info":{"name":"python","version":"3.6.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernel_info":{"name":"python3-azureml"},"nteract":{"version":"nteract-front-end@1.0.0"}},"nbformat":4,"nbformat_minor":2}